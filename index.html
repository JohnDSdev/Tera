<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>Gemini Voice Assistant (No Backend)</title>
<style>
body{
  font-family:system-ui, sans-serif;
  background:#0b0d10;color:#e5e7eb;
  display:flex;flex-direction:column;align-items:center;justify-content:center;
  height:100vh;margin:0;text-align:center;
}
button{
  background:#14b8a6;border:none;border-radius:8px;
  color:#fff;padding:10px 20px;font-size:1rem;
  margin:8px;cursor:pointer;transition:background .2s;
}
button:hover{background:#0d9488}
#status{margin-top:15px;font-size:1.1rem;color:#a5f3fc}
</style>
</head>
<body>
<h2>ðŸŽ™ Gemini Voice Assistant</h2>
<button id="connectBtn">Connect</button>
<button id="talkBtn" disabled>Start talking</button>
<p id="status">Idle</p>

<script>
let GEMINI_KEY = null;
let mediaRecorder, chunks = [];

const statusEl = document.getElementById('status');
const connectBtn = document.getElementById('connectBtn');
const talkBtn = document.getElementById('talkBtn');

connectBtn.onclick = () => {
  GEMINI_KEY = prompt("Enter your Gemini API key:");
  if(GEMINI_KEY){
    statusEl.textContent = "Connected âœ…";
    talkBtn.disabled = false;
  }
};

async function recordAudio(){
  const stream = await navigator.mediaDevices.getUserMedia({audio:true});
  chunks = [];
  mediaRecorder = new MediaRecorder(stream);
  mediaRecorder.ondataavailable = e => chunks.push(e.data);
  mediaRecorder.start();
  statusEl.textContent = "Listening... (speak for a few seconds)";
  return new Promise(resolve=>{
    setTimeout(()=>{
      mediaRecorder.stop();
      mediaRecorder.onstop = async ()=>{
        const blob = new Blob(chunks, {type:'audio/webm'});
        resolve(blob);
      };
    },4000); // record 4 seconds
  });
}

async function sttGemini(audioBlob){
  const arrayBuffer = await audioBlob.arrayBuffer();
  const base64 = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
  const body = {
    contents: [{
      role:"user",
      parts:[{
        inlineData:{ mimeType:"audio/webm", data: base64 }
      }]
    }]
  };
  const res = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_KEY}`,{
    method:"POST",
    headers:{"Content-Type":"application/json"},
    body:JSON.stringify(body)
  });
  const j = await res.json();
  const text = j?.candidates?.[0]?.content?.parts?.[0]?.text || "";
  return text.trim();
}

async function generateReply(prompt){
  const body = {
    contents:[{role:"user", parts:[{text:prompt}]}]
  };
  const res = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_KEY}`,{
    method:"POST",
    headers:{"Content-Type":"application/json"},
    body:JSON.stringify(body)
  });
  const j = await res.json();
  return j?.candidates?.[0]?.content?.parts?.[0]?.text?.trim() || "";
}

async function ttsGemini(text){
  const res = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:speech?key=${GEMINI_KEY}`,{
    method:"POST",
    headers:{"Content-Type":"application/json"},
    body:JSON.stringify({
      input:{text},
      voice:{languageCode:"en-US"},
      audioConfig:{audioEncoding:"MP3"}
    })
  });
  const j = await res.json();
  const audioB64 = j.audioContent;
  const audio = new Audio("data:audio/mp3;base64,"+audioB64);
  audio.play();
}

talkBtn.onclick = async ()=>{
  talkBtn.disabled = true;
  statusEl.textContent = "Recording...";
  const audioBlob = await recordAudio();
  statusEl.textContent = "Processing speech...";
  const transcript = await sttGemini(audioBlob);
  if(!transcript){statusEl.textContent="Didnâ€™t catch that.";talkBtn.disabled=false;return;}
  statusEl.textContent = "You said: "+transcript;
  const reply = await generateReply(transcript);
  statusEl.textContent = "Gemini: "+reply;
  await ttsGemini(reply);
  talkBtn.disabled = false;
};
</script>
</body>
</html>
