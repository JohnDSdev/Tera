diff --git a/index.html b/index.html
index 5c62ce463f26b2ecaef9605561a9b43b15fbceef..a82d7cd5f6ae47665e75283b239c6ff41f13e343 100644
--- a/index.html
+++ b/index.html
@@ -1,233 +1,719 @@
 <!DOCTYPE html>
 <html lang="en">
 <head>
   <meta charset="UTF-8">
-  <meta name="viewport" content="width=device-width, initial-scale=1">
-  <title>Gemini Live Voice Chat (Demo)</title>
+  <meta name="viewport" content="width=device-width, initial-scale=1.0">
+  <title>Gemini Voice AI</title>
   <style>
+    :root {
+      color-scheme: only light;
+      --accent: #2962ff;
+      --accent-dark: #0039cb;
+      --bg: #ffffff;
+      --text: #141414;
+      --muted: #667085;
+      font-family: "Inter", system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
+    }
+
+    * {
+      box-sizing: border-box;
+    }
+
     body {
-      font-family: Arial, sans-serif;
-      max-width: 600px;
-      margin: 2rem auto;
-      padding: 1rem;
-      background: #fafafa;
+      margin: 0;
+      min-height: 100vh;
+      background: var(--bg);
+      color: var(--text);
+      display: flex;
+      justify-content: center;
+      align-items: stretch;
+      padding: clamp(16px, 5vw, 48px);
+    }
+
+    .app {
+      width: min(960px, 100%);
+      background: #f6f7fb;
+      border-radius: 28px;
+      box-shadow: 0 32px 70px rgba(20, 20, 43, 0.18);
+      overflow: hidden;
+      display: grid;
+      grid-template-rows: auto 1fr auto;
+    }
+
+    header {
+      padding: 28px clamp(24px, 5vw, 48px);
+      background: linear-gradient(120deg, rgba(41, 98, 255, 0.16), rgba(6, 64, 255, 0));
+      border-bottom: 1px solid rgba(15, 23, 42, 0.06);
+    }
+
+    header h1 {
+      margin: 0 0 6px;
+      font-size: clamp(1.6rem, 2.4vw + 1rem, 2.4rem);
+      font-weight: 700;
+      letter-spacing: -0.04em;
+    }
+
+    header p {
+      margin: 0;
+      color: var(--muted);
+      font-size: 0.95rem;
+    }
+
+    .connection {
+      display: flex;
+      flex-wrap: wrap;
+      gap: 12px;
+      margin-top: 18px;
+      align-items: center;
+    }
+
+    .connection input {
+      flex: 1 1 220px;
+      padding: 12px 16px;
+      border-radius: 14px;
+      border: 1px solid rgba(15, 23, 42, 0.12);
+      background: #fff;
+      font-size: 0.95rem;
+    }
+
+    .connection button {
+      border: none;
+      border-radius: 14px;
+      padding: 12px 20px;
+      font-weight: 600;
+      font-size: 0.95rem;
+      cursor: pointer;
+      transition: transform 0.2s ease, box-shadow 0.2s ease;
+    }
+
+    #connectBtn {
+      background: var(--accent);
+      color: #fff;
+      box-shadow: 0 12px 22px rgba(41, 98, 255, 0.28);
+    }
+
+    #connectBtn:disabled {
+      background: rgba(41, 98, 255, 0.42);
+      cursor: not-allowed;
+      box-shadow: none;
+    }
+
+    #connectBtn:not(:disabled):hover {
+      transform: translateY(-1px);
+      box-shadow: 0 18px 28px rgba(41, 98, 255, 0.34);
+    }
+
+    .status-bar {
+      display: flex;
+      align-items: center;
+      gap: 12px;
+      color: var(--muted);
+      font-size: 0.9rem;
+    }
+
+    .status-indicator {
+      width: 10px;
+      height: 10px;
+      border-radius: 50%;
+      background: #d1d5db;
+      box-shadow: 0 0 0 4px rgba(209, 213, 219, 0.35);
+      transition: background 0.3s ease, box-shadow 0.3s ease;
+    }
+
+    .status-indicator.online {
+      background: #10b981;
+      box-shadow: 0 0 0 4px rgba(16, 185, 129, 0.25);
     }
-    h1 {
-      text-align: center;
+
+    main {
+      display: grid;
+      grid-template-columns: minmax(260px, 340px) 1fr;
+      gap: clamp(24px, 4vw, 48px);
+      padding: clamp(24px, 5vw, 48px);
     }
-    #status {
-      margin: 1rem 0;
-      font-weight: bold;
+
+    @media (max-width: 880px) {
+      main {
+        grid-template-columns: 1fr;
+      }
+      .avatar-stage {
+        order: -1;
+        margin-inline: auto;
+      }
     }
-    #log {
-      white-space: pre-wrap;
+
+    .avatar-stage {
       background: #fff;
-      border: 1px solid #ccc;
-      padding: 0.5rem;
-      height: 200px;
-      overflow-y: scroll;
+      border-radius: 24px;
+      padding: 24px;
+      display: flex;
+      justify-content: center;
+      align-items: center;
+      position: relative;
+      min-height: 320px;
+      overflow: hidden;
     }
-    #controls {
-      margin: 1rem 0;
+
+    .avatar-stage::after {
+      content: "";
+      position: absolute;
+      inset: 24px;
+      border-radius: 20px;
+      background: radial-gradient(circle at top, rgba(41, 98, 255, 0.12), transparent 60%);
+      z-index: 0;
     }
-    label, input, button {
+
+    .avatar-stage img {
+      width: min(260px, 100%);
+      object-fit: contain;
+      position: relative;
+      z-index: 1;
+      filter: drop-shadow(0 24px 50px rgba(15, 23, 42, 0.25));
+      transition: transform 0.4s ease;
+    }
+
+    .avatar-stage img.speaking {
+      transform: translateY(-6px) scale(1.02);
+    }
+
+    .conversation-panel {
+      background: #fff;
+      border-radius: 24px;
+      padding: clamp(20px, 4vw, 32px);
+      display: flex;
+      flex-direction: column;
+      min-height: 320px;
+      box-shadow: inset 0 0 0 1px rgba(15, 23, 42, 0.04);
+    }
+
+    .messages {
+      flex: 1;
+      overflow-y: auto;
+      padding-right: 8px;
+      scrollbar-width: thin;
+      display: flex;
+      flex-direction: column;
+      gap: 18px;
+    }
+
+    .messages::-webkit-scrollbar {
+      width: 6px;
+    }
+
+    .messages::-webkit-scrollbar-thumb {
+      background: rgba(41, 98, 255, 0.3);
+      border-radius: 999px;
+    }
+
+    .bubble {
+      padding: 14px 16px;
+      border-radius: 18px;
+      line-height: 1.48;
+      max-width: 100%;
+      word-break: break-word;
+      font-size: 0.98rem;
+      animation: fadeUp 0.35s ease;
+    }
+
+    .bubble.user {
+      align-self: flex-end;
+      background: rgba(41, 98, 255, 0.14);
+      color: #1a2a6c;
+      border-bottom-right-radius: 4px;
+    }
+
+    .bubble.ai {
+      align-self: flex-start;
+      background: rgba(15, 23, 42, 0.05);
+      border-bottom-left-radius: 4px;
+    }
+
+    @keyframes fadeUp {
+      from {
+        opacity: 0;
+        transform: translateY(6px);
+      }
+      to {
+        opacity: 1;
+        transform: translateY(0);
+      }
+    }
+
+    .transcript-note {
+      color: var(--muted);
+      font-size: 0.85rem;
+      margin-top: 4px;
+    }
+
+    footer {
+      padding: clamp(16px, 4vw, 28px) clamp(24px, 5vw, 48px) 32px;
+      border-top: 1px solid rgba(15, 23, 42, 0.06);
+      background: #f8f9ff;
+      display: flex;
+      flex-direction: column;
+      gap: 18px;
+    }
+
+    .talk-controls {
+      display: flex;
+      flex-wrap: wrap;
+      gap: 16px;
+      align-items: center;
+      justify-content: space-between;
+    }
+
+    #talkBtn {
+      border: none;
+      border-radius: 999px;
+      padding: 18px 42px;
       font-size: 1rem;
+      font-weight: 600;
+      background: var(--accent);
+      color: #fff;
+      box-shadow: 0 18px 36px rgba(41, 98, 255, 0.25);
+      cursor: pointer;
+      transition: transform 0.2s ease, box-shadow 0.2s ease, background 0.2s ease;
     }
-    input[type="password"] {
-      width: 70%;
-      padding: 0.4rem;
+
+    #talkBtn:disabled {
+      background: rgba(41, 98, 255, 0.38);
+      cursor: not-allowed;
+      box-shadow: none;
     }
-    button {
-      padding: 0.5rem 1rem;
-      margin-left: 0.5rem;
+
+    #talkBtn.recording {
+      background: #ef4444;
+      box-shadow: 0 18px 32px rgba(239, 68, 68, 0.35);
+    }
+
+    #talkBtn:not(:disabled):active {
+      transform: scale(0.97);
+    }
+
+    .hint {
+      color: var(--muted);
+      font-size: 0.85rem;
+    }
+
+    audio {
+      display: none;
     }
   </style>
 </head>
 <body>
-  <h1>Gemini Live Voice Chat</h1>
-  <div id="status">Idle</div>
-  <div id="controls">
-    <label for="apikey">API Key:</label>
-    <input type="password" id="apikey" placeholder="Enter Gemini key">
-    <button id="btnConnect">Connect & Talk</button>
-    <button id="btnDisconnect" disabled>Disconnect</button>
+  <div class="app">
+    <header>
+      <h1>Gemini Voice AI</h1>
+      <p>Hold to talk, release to send. Gemini handles transcription, conversation, and speech back to you.</p>
+      <div class="connection">
+        <input type="password" id="apiKey" placeholder="Enter your Gemini API key" autocomplete="off">
+        <button id="connectBtn">Connect</button>
+        <div class="status-bar">
+          <span class="status-indicator" id="statusIndicator"></span>
+          <span id="statusText">Disconnected</span>
+        </div>
+      </div>
+    </header>
+
+    <main>
+      <section class="avatar-stage">
+        <img id="avatar" alt="AI avatar" src="a7.png">
+      </section>
+      <section class="conversation-panel">
+        <div class="messages" id="messages"></div>
+      </section>
+    </main>
+
+    <footer>
+      <div class="talk-controls">
+        <button id="talkBtn" disabled>Hold to talk</button>
+        <span class="hint" id="hintText">Connect with your API key to begin.</span>
+      </div>
+    </footer>
   </div>
-  <div id="log"></div>
+
+  <audio id="responseAudio"></audio>
 
   <script>
-    const statusEl = document.getElementById("status");
-    const logEl = document.getElementById("log");
-    const btnConnect = document.getElementById("btnConnect");
-    const btnDisconnect = document.getElementById("btnDisconnect");
-    const inputApiKey = document.getElementById("apikey");
+    const apiKeyInput = document.getElementById('apiKey');
+    const connectBtn = document.getElementById('connectBtn');
+    const talkBtn = document.getElementById('talkBtn');
+    const statusIndicator = document.getElementById('statusIndicator');
+    const statusText = document.getElementById('statusText');
+    const messagesEl = document.getElementById('messages');
+    const hintText = document.getElementById('hintText');
+    const avatarEl = document.getElementById('avatar');
+    const responseAudio = document.getElementById('responseAudio');
+
+    const startupFrames = ['a1.png', 'a2.png', 'a3.png', 'a4.png', 'a5.png', 'a6.png', 'a7.png'];
+    const idleFrame = 'arm_behind_mouth_closed.png';
+    const speakingFrames = [
+      'arm_out_mouth_open.png',
+      'arm_out_mouth_closed.png',
+      'arm_behind_mouth_open.png',
+      'arm_behind_mouth_closed.png'
+    ];
 
-    let socket = null;
+    const imageCache = new Map();
+    [...startupFrames, idleFrame, ...speakingFrames].forEach(src => {
+      const img = new Image();
+      img.src = src;
+      imageCache.set(src, img);
+    });
+
+    let apiKey = '';
+    let connected = false;
+    let mediaStream = null;
+    let mediaRecorder = null;
+    let chunks = [];
+    let isRecording = false;
+    let speakingInterval = null;
     let audioContext = null;
-    let micStream = null;
-    let processor = null;
 
-    function log(msg) {
-      console.log(msg);
-      logEl.textContent += msg + "\\n";
-      logEl.scrollTop = logEl.scrollHeight;
+    const systemInstruction = {
+      role: 'system',
+      parts: [{ text: 'You are a futuristic but friendly AI guide. Keep responses under 120 words and speak naturally.' }]
+    };
+
+    const conversationHistory = [];
+
+    function updateStatus(online, text) {
+      statusIndicator.classList.toggle('online', Boolean(online));
+      statusText.textContent = text;
+    }
+
+    function addMessage(role, text, note) {
+      const bubble = document.createElement('div');
+      bubble.className = `bubble ${role}`;
+      bubble.textContent = text;
+      messagesEl.appendChild(bubble);
+      if (note) {
+        const small = document.createElement('div');
+        small.className = 'transcript-note';
+        small.textContent = note;
+        bubble.appendChild(small);
+      }
+      messagesEl.scrollTop = messagesEl.scrollHeight;
+    }
+
+    function setAvatar(frame, speaking = false) {
+      avatarEl.src = frame;
+      avatarEl.classList.toggle('speaking', speaking);
+    }
+
+    async function playStartupSequence() {
+      await playStartupSound();
+      for (let i = 0; i < startupFrames.length; i++) {
+        setAvatar(startupFrames[i]);
+        await wait(160);
+      }
+      setAvatar(idleFrame);
+    }
+
+    async function playStartupSound() {
+      try {
+        if (!audioContext) {
+          audioContext = new (window.AudioContext || window.webkitAudioContext)();
+        }
+        const osc = audioContext.createOscillator();
+        const osc2 = audioContext.createOscillator();
+        const gain = audioContext.createGain();
+        osc.type = 'sawtooth';
+        osc.frequency.setValueAtTime(320, audioContext.currentTime);
+        osc.frequency.exponentialRampToValueAtTime(880, audioContext.currentTime + 1.1);
+        osc2.type = 'triangle';
+        osc2.frequency.setValueAtTime(120, audioContext.currentTime);
+        osc2.frequency.linearRampToValueAtTime(420, audioContext.currentTime + 1.1);
+        gain.gain.setValueAtTime(0.0001, audioContext.currentTime);
+        gain.gain.exponentialRampToValueAtTime(0.6, audioContext.currentTime + 0.2);
+        gain.gain.exponentialRampToValueAtTime(0.0001, audioContext.currentTime + 1.2);
+        osc.connect(gain);
+        osc2.connect(gain);
+        gain.connect(audioContext.destination);
+        osc.start();
+        osc2.start();
+        osc.stop(audioContext.currentTime + 1.25);
+        osc2.stop(audioContext.currentTime + 1.25);
+      } catch (err) {
+        console.warn('Startup sound failed', err);
+      }
     }
-    function setStatus(s) {
-      statusEl.textContent = s;
+
+    function wait(ms) {
+      return new Promise(resolve => setTimeout(resolve, ms));
     }
 
-    btnConnect.onclick = async () => {
-      const key = inputApiKey.value.trim();
+    connectBtn.addEventListener('click', async () => {
+      if (connected) {
+        disconnect();
+        return;
+      }
+
+      const key = apiKeyInput.value.trim();
       if (!key) {
-        alert("Please enter your API key");
+        alert('Please enter your Gemini API key.');
         return;
       }
-      btnConnect.disabled = true;
-      setStatus("Requesting mic...");
+      apiKey = key;
+      connectBtn.disabled = true;
+      hintText.textContent = 'Requesting microphone access…';
+
       try {
-        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
+        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
       } catch (err) {
-        setStatus("Mic access error");
-        log("Mic error: " + err);
-        btnConnect.disabled = false;
+        console.error(err);
+        alert('Microphone permission is required to use voice chat.');
+        connectBtn.disabled = false;
+        hintText.textContent = 'Microphone permission denied.';
         return;
       }
 
-      audioContext = new AudioContext({ sampleRate: 16000 }); // request 16kHz input if possible
-      const source = audioContext.createMediaStreamSource(micStream);
-      processor = audioContext.createScriptProcessor(4096, 1, 1);
-      source.connect(processor);
-      processor.connect(audioContext.destination);
-      processor.onaudioprocess = (e) => {
-        const input = e.inputBuffer.getChannelData(0);
-        const pcm16 = float32ToInt16(input);
-        const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
-        const msg = {
-          realtimeInput: {
-            mediaChunks: [
-              {
-                data: base64,
-                mimeType: "audio/pcm"
-              }
-            ]
-          }
-        };
-        if (socket && socket.readyState === WebSocket.OPEN) {
-          socket.send(JSON.stringify(msg));
+      await playStartupSequence();
+      setupRecorder();
+      connected = true;
+      connectBtn.textContent = 'Disconnect';
+      connectBtn.disabled = false;
+      talkBtn.disabled = false;
+      hintText.textContent = 'Hold the button, speak, then release to send.';
+      updateStatus(true, 'Ready');
+      conversationHistory.length = 0;
+    });
+
+    function disconnect() {
+      connected = false;
+      apiKey = '';
+      connectBtn.textContent = 'Connect';
+      talkBtn.disabled = true;
+      connectBtn.disabled = false;
+      hintText.textContent = 'Connect with your API key to begin.';
+      updateStatus(false, 'Disconnected');
+      setAvatar(idleFrame, false);
+      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
+        mediaRecorder.stop();
+      }
+      if (mediaStream) {
+        mediaStream.getTracks().forEach(track => track.stop());
+        mediaStream = null;
+      }
+      if (speakingInterval) {
+        clearInterval(speakingInterval);
+        speakingInterval = null;
+      }
+      conversationHistory.length = 0;
+    }
+
+    function setupRecorder() {
+      if (!mediaStream) return;
+      mediaRecorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm;codecs=opus' });
+      mediaRecorder.ondataavailable = event => {
+        if (event.data && event.data.size > 0) {
+          chunks.push(event.data);
         }
       };
-
-      setStatus("Connecting WebSocket...");
-      const wsUrl = "wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent";
-      // include API key in query param (or may need to use header depending on API)
-      socket = new WebSocket(wsUrl + "?key=" + encodeURIComponent(key));
-      socket.binaryType = "arraybuffer";
-
-      socket.onopen = () => {
-        setStatus("Connected. Sending setup...");
-        log("WebSocket open");
-        const setupMsg = {
-          setup: {
-            model: "gemini-live-2.5-flash-preview-native-audio-09-2025",  // choose appropriate model
-            generationConfig: {
-              responseModalities: ["AUDIO"],
-              speechConfig: {
-                // voice configuration if needed
-              }
-            }
-            // systemInstruction, tools etc can go here
-          }
-        };
-        socket.send(JSON.stringify(setupMsg));
+      mediaRecorder.onstop = async () => {
+        if (!chunks.length) return;
+        const blob = new Blob(chunks, { type: 'audio/webm;codecs=opus' });
+        chunks = [];
+        await handleRecording(blob);
       };
+    }
 
-      socket.onmessage = (evt) => {
-        // All messages are JSON (text). Any audio is inline base64 in JSON.
-        const txt = evt.data;
-        try {
-          const obj = JSON.parse(txt);
-          log("Received: " + JSON.stringify(obj));
-          // Look for server message containing audio
-          if (obj.serverContent && obj.serverContent.modelTurn && obj.serverContent.modelTurn.parts) {
-            for (const part of obj.serverContent.modelTurn.parts) {
-              if (part.inlineData && part.inlineData.data) {
-                const b64 = part.inlineData.data;
-                const audioBytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));
-                playPCM24(audioBytes.buffer);
-              }
-            }
-          }
-        } catch (err) {
-          log("JSON parse error: " + err + " msg: " + evt.data);
+    async function handleRecording(blob) {
+      updateStatus(true, 'Processing speech…');
+      addMessage('user', '…', 'Transcribing audio');
+      try {
+        const transcript = await transcribeWithGemini(blob);
+        if (!transcript) {
+          throw new Error('No transcript returned');
         }
-      };
+        replaceLastUserPlaceholder(transcript);
+        conversationHistory.push({ role: 'user', parts: [{ text: transcript }] });
+        updateStatus(true, 'Thinking…');
+        const response = await respondWithGemini();
+        if (!response) {
+          throw new Error('No response from Gemini');
+        }
+        const { text, audio } = response;
+        if (text) {
+          addMessage('ai', text);
+        }
+        if (audio) {
+          await playResponseAudio(audio);
+        } else {
+          setAvatar(idleFrame);
+        }
+        updateStatus(true, 'Ready');
+      } catch (err) {
+        console.error(err);
+        updateStatus(false, 'Error');
+        replaceLastUserPlaceholder('Audio could not be processed.');
+        addMessage('ai', 'I ran into a problem handling that message. Please try again.');
+      }
+    }
+
+    function replaceLastUserPlaceholder(text) {
+      const bubbles = messagesEl.querySelectorAll('.bubble.user');
+      if (!bubbles.length) return;
+      const last = bubbles[bubbles.length - 1];
+      last.firstChild.textContent = text;
+      const note = last.querySelector('.transcript-note');
+      if (note) note.remove();
+    }
 
-      socket.onerror = (err) => {
-        setStatus("Socket error");
-        log("Socket error: " + err);
+    async function transcribeWithGemini(blob) {
+      const base64 = await blobToBase64(blob);
+      const body = {
+        contents: [
+          {
+            role: 'user',
+            parts: [
+              { text: 'Transcribe the following audio faithfully. Respond with text only.' },
+              { inlineData: { mimeType: blob.type || 'audio/webm', data: base64 } }
+            ]
+          }
+        ]
       };
 
-      socket.onclose = (evt) => {
-        setStatus("Disconnected");
-        log("Socket closed: " + evt.reason);
-        cleanup();
+      const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${encodeURIComponent(apiKey)}`, {
+        method: 'POST',
+        headers: { 'Content-Type': 'application/json' },
+        body: JSON.stringify(body)
+      });
+
+      if (!response.ok) {
+        const errorText = await response.text();
+        throw new Error('Transcription failed: ' + errorText);
+      }
+
+      const data = await response.json();
+      const text = data?.candidates?.[0]?.content?.parts?.map(part => part.text || '').join('').trim();
+      return text || '';
+    }
+
+    async function respondWithGemini() {
+      const body = {
+        contents: [systemInstruction, ...conversationHistory],
+        generationConfig: {
+          responseMimeType: 'audio/ogg'
+        }
       };
 
-      btnDisconnect.disabled = false;
-    };
+      const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${encodeURIComponent(apiKey)}`, {
+        method: 'POST',
+        headers: { 'Content-Type': 'application/json' },
+        body: JSON.stringify(body)
+      });
 
-    btnDisconnect.onclick = () => {
-      if (socket) socket.close();
-      cleanup();
-      setStatus("Idle");
-      btnConnect.disabled = false;
-      btnDisconnect.disabled = true;
-    };
+      if (!response.ok) {
+        const errorText = await response.text();
+        throw new Error('Response failed: ' + errorText);
+      }
 
-    function cleanup() {
-      if (processor) {
-        processor.disconnect();
-        processor = null;
+      const data = await response.json();
+      const parts = data?.candidates?.[0]?.content?.parts || [];
+      const text = parts.filter(part => part.text).map(part => part.text).join('').trim();
+      const inline = parts.find(part => part.inlineData && part.inlineData.data);
+      const audio = inline ? { data: inline.inlineData.data, mimeType: inline.inlineData.mimeType || 'audio/ogg' } : null;
+      if (text) {
+        conversationHistory.push({ role: 'model', parts: [{ text }] });
       }
-      if (audioContext) {
-        audioContext.close();
-        audioContext = null;
+      if (audio && !text) {
+        conversationHistory.push({ role: 'model', parts: [{ inlineData: { data: audio.data, mimeType: audio.mimeType } }] });
       }
-      if (micStream) {
-        micStream.getTracks().forEach(t => t.stop());
-        micStream = null;
+      return { text, audio };
+    }
+
+    async function playResponseAudio(audioPart) {
+      const buffer = base64ToArrayBuffer(audioPart.data);
+      const blob = new Blob([buffer], { type: audioPart.mimeType || 'audio/ogg' });
+      const url = URL.createObjectURL(blob);
+      responseAudio.src = url;
+      setAvatar(speakingFrames[0], true);
+      let frameIndex = 0;
+      if (speakingInterval) clearInterval(speakingInterval);
+      speakingInterval = setInterval(() => {
+        frameIndex = (frameIndex + 1) % speakingFrames.length;
+        const frame = speakingFrames[frameIndex];
+        const speaking = frame.includes('open');
+        setAvatar(frame, speaking);
+      }, 180);
+
+      await responseAudio.play().catch(err => {
+        console.warn('Autoplay blocked', err);
+      });
+
+      responseAudio.onended = () => {
+        if (speakingInterval) {
+          clearInterval(speakingInterval);
+          speakingInterval = null;
+        }
+        setAvatar(idleFrame, false);
+        URL.revokeObjectURL(url);
+      };
+    }
+
+    function base64ToArrayBuffer(base64) {
+      const binary = atob(base64);
+      const len = binary.length;
+      const bytes = new Uint8Array(len);
+      for (let i = 0; i < len; i++) {
+        bytes[i] = binary.charCodeAt(i);
       }
-      socket = null;
+      return bytes.buffer;
     }
 
-    function float32ToInt16(buf) {
-      const l = buf.length;
-      const out = new Int16Array(l);
-      for (let i = 0; i < l; i++) {
-        let s = Math.max(-1, Math.min(1, buf[i]));
-        out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
+    function blobToBase64(blob) {
+      return new Promise((resolve, reject) => {
+        const reader = new FileReader();
+        reader.onloadend = () => {
+          const base64 = reader.result.split(',')[1];
+          resolve(base64);
+        };
+        reader.onerror = reject;
+        reader.readAsDataURL(blob);
+      });
+    }
+
+    ['mousedown', 'touchstart'].forEach(eventName => {
+      talkBtn.addEventListener(eventName, startRecording);
+    });
+
+    ['mouseup', 'mouseleave', 'touchend', 'touchcancel'].forEach(eventName => {
+      talkBtn.addEventListener(eventName, stopRecording);
+    });
+
+    async function startRecording(event) {
+      if (!connected || !mediaRecorder) return;
+      event.preventDefault();
+      if (mediaRecorder.state === 'recording') return;
+      talkBtn.classList.add('recording');
+      talkBtn.textContent = 'Listening…';
+      updateStatus(true, 'Listening…');
+      addMessage('user', '…', 'Recording audio');
+      chunks = [];
+      mediaRecorder.start();
+      isRecording = true;
+    }
+
+    function stopRecording(event) {
+      if (!connected || !mediaRecorder || !isRecording) return;
+      event.preventDefault();
+      talkBtn.classList.remove('recording');
+      talkBtn.textContent = 'Hold to talk';
+      isRecording = false;
+      if (mediaRecorder.state === 'recording') {
+        mediaRecorder.stop();
       }
-      return out;
     }
 
-    function playPCM24(arrayBuffer) {
-      // Output from server is 16-bit PCM at 24 kHz (per spec)
-      // Convert 16-bit PCM @24k to Float32, then play
-      if (!audioContext) {
-        audioContext = new AudioContext();
+    window.addEventListener('beforeunload', () => {
+      if (audioContext) {
+        audioContext.close();
       }
-      const pcm16 = new Int16Array(arrayBuffer);
-      const float32 = new Float32Array(pcm16.length);
-      for (let i = 0; i < pcm16.length; i++) {
-        float32[i] = pcm16[i] / 32768;
+      if (mediaStream) {
+        mediaStream.getTracks().forEach(track => track.stop());
       }
-      // Create AudioBuffer at 24000 Hz
-      const buf = audioContext.createBuffer(1, float32.length, 24000);
-      buf.copyToChannel(float32, 0);
-      const src = audioContext.createBufferSource();
-      src.buffer = buf;
-      src.connect(audioContext.destination);
-      src.start();
-    }
+    });
   </script>
 </body>
 </html>
