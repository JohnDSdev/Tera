<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>Gemini Live Hologram â€“ Anti-Flicker</title>
<style>
body{
  background:#050510;color:#7df;font-family:monospace;
  display:flex;flex-direction:column;align-items:center;justify-content:center;
  height:100vh;margin:0;
}
#avatar{
  width:64px;height:128px;
  image-rendering:pixelated;
  filter:drop-shadow(0 0 8px #0ff);
  opacity:0;transition:opacity 1s ease;
}
#status{margin:8px}
button,select{
  margin:5px;padding:8px 14px;border:none;border-radius:5px;
  background:#0ff;color:#000;font-weight:bold;cursor:pointer;
}
button:disabled{opacity:.4}
select{font-weight:600}
</style>
</head>
<body>
<div id="status">Status: idle</div>
<img id="avatar" src="arm_behind_mouth_closed.png" alt="avatar">
<div>
  <select id="voice">
    <option value="Zephyr">Zephyr</option>
    <option value="Aria">Aria</option>
    <option value="Breeze">Breeze</option>
    <option value="Nova">Nova</option>
    <option value="Orbit">Orbit</option>
    <option value="Solstice">Solstice</option>
    <option value="Sable">Sable</option>
    <option value="Dune">Dune</option>
  </select>
  <button id="connect">Connect</button>
  <button id="end" disabled>End</button>
</div>

<script type="module">
import { GoogleGenAI, Modality } from "https://aistudiocdn.com/@google/genai@1.24.0";

const avatar=document.getElementById("avatar");
const statusEl=document.getElementById("status");
const connectBtn=document.getElementById("connect");
const endBtn=document.getElementById("end");
const voiceSel=document.getElementById("voice");

const frames={
  armClosed:"arm_out_mouth_closed.png",
  armOpen:"arm_out_mouth_open.png",
  backClosed:"arm_behind_mouth_closed.png",
  backOpen:"arm_behind_mouth_open.png"
};

let ai,session,micStream,inCtx,outCtx,analyser;
let mouthRAF=null,pose=0,closing=false;
let nextStartTime=0,queueLen=0;
let smoothRMS=0;

function setStatus(t){statusEl.textContent="Status: "+t;}
function setFrame(open){
  if(pose===0)avatar.src=open?frames.backOpen:frames.backClosed;
  else avatar.src=open?frames.armOpen:frames.armClosed;
}

/* ====== MOUTH ANIMATION (non-blocking) ====== */
function startMouth(){
  if(mouthRAF) return;
  const buffer=new Uint8Array(analyser.fftSize);
  const animate=()=>{
    analyser.getByteTimeDomainData(buffer);
    let sum=0;
    for(let i=0;i<buffer.length;i++){
      const f=(buffer[i]-128)/128; sum+=f*f;
    }
    const rms=Math.sqrt(sum/buffer.length);
    smoothRMS=0.85*smoothRMS+0.15*rms; // smoothing filter
    const open=smoothRMS>0.02;
    if(smoothRMS>0.05)pose=pose?0:1;
    setFrame(open);
    mouthRAF=requestAnimationFrame(animate);
  };
  mouthRAF=requestAnimationFrame(animate);
}
function stopMouth(){
  if(mouthRAF){cancelAnimationFrame(mouthRAF);mouthRAF=null;}
  setFrame(false);
}

/* ====== CONNECT ====== */
connectBtn.onclick=async()=>{
  if(session){setStatus("Already connected.");return;}
  closing=false;
  const key=prompt("Enter your Gemini API key:"); if(!key)return;
  const chosenVoice=voiceSel.value;
  setStatus("Connecting...");
  ai=new GoogleGenAI({apiKey:key});
  inCtx=new AudioContext({sampleRate:16000});
  outCtx=new AudioContext({});
  analyser=outCtx.createAnalyser();
  analyser.fftSize=512;
  analyser.connect(outCtx.destination);

  try{micStream=await navigator.mediaDevices.getUserMedia({audio:true});}
  catch(e){setStatus("Mic permission denied");return;}

  const micSrc=inCtx.createMediaStreamSource(micStream);
  const proc=inCtx.createScriptProcessor(4096,1,1);
  micSrc.connect(proc);proc.connect(inCtx.destination);

  session=await ai.live.connect({
    model:"gemini-2.5-flash-native-audio-preview-09-2025",
    callbacks:{
      onopen:()=>{setStatus("Connected");avatar.style.opacity=1;},
      onmessage:onMessage,
      onerror:e=>setStatus("Error: "+e.message),
      onclose:()=>{if(!closing)setStatus("Disconnected");session=null;}
    },
    config:{
      responseModalities:[Modality.AUDIO],
      speechConfig:{voiceConfig:{prebuiltVoiceConfig:{voiceName:chosenVoice}}},
      systemInstruction:"You are a natural, single holographic AI voice. Avoid overlapping playback."
    }
  });

  proc.onaudioprocess=e=>{
    if(!session)return;
    const d=e.inputBuffer.getChannelData(0);
    const i16=new Int16Array(d.length);
    for(let i=0;i<d.length;i++)i16[i]=d[i]*32768;
    const b64=btoa(String.fromCharCode(...new Uint8Array(i16.buffer)));
    session.sendRealtimeInput({media:{data:b64,mimeType:"audio/pcm;rate=16000"}});
  };

  connectBtn.disabled=true; endBtn.disabled=false;
  setStatus("Live voice chat ready.");
};

/* ====== AUDIO QUEUE (anti-flicker) ====== */
function onMessage(msg){
  const data=msg.serverContent?.modelTurn?.parts?.[0]?.inlineData?.data;
  if(!data||!outCtx)return;
  const bytes=Uint8Array.from(atob(data),c=>c.charCodeAt(0));
  const int16=new Int16Array(bytes.buffer);
  const buf=outCtx.createBuffer(1,int16.length,24000);
  const ch=buf.getChannelData(0);
  for(let i=0;i<int16.length;i++)ch[i]=int16[i]/32768;

  // Lightweight fade to remove clicks
  const fade=0.03; const fS=Math.floor(fade*buf.sampleRate);
  for(let i=0;i<fS;i++){
    const x=i/fS; ch[i]*=x; ch[ch.length-1-i]*=x;
  }

  // simple sequential scheduler with drift correction
  const now=outCtx.currentTime;
  if(Math.abs(nextStartTime-now)>0.3) nextStartTime=now;
  const startAt=Math.max(now,nextStartTime);
  nextStartTime=startAt+buf.duration-0.01;

  const src=outCtx.createBufferSource();
  src.buffer=buf; src.connect(analyser);
  if(outCtx.state==="suspended") outCtx.resume();
  src.start(startAt);
  startMouth();
  src.onended=()=>stopMouth();
}

/* ====== END / CLEANUP ====== */
endBtn.onclick=()=>{
  closing=true; setStatus("Closing...");
  if(session){try{session.close();}catch{} session=null;}
  if(micStream)micStream.getTracks().forEach(t=>t.stop());
  if(inCtx)inCtx.close(); if(outCtx)outCtx.close();
  connectBtn.disabled=false; endBtn.disabled=true;
  stopMouth(); setFrame(false);
  setStatus("Idle");
};
</script>
</body>
</html>
