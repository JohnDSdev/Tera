<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Gemini Voice AI Console</title>
  <style>
    :root {
      color-scheme: only light;
      --accent: #2662ff;
      --accent-dark: #0c37c7;
      --surface: #f5f7fb;
      --border: #e2e8f0;
      --text: #0f172a;
      --muted: #64748b;
      font-family: "Inter", system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background: #ffffff;
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: clamp(24px, 6vw, 64px);
      background: #ffffff;
      color: var(--text);
    }

    .shell {
      width: min(1080px, 100%);
      background: var(--surface);
      border-radius: 32px;
      box-shadow: 0 32px 80px rgba(15, 23, 42, 0.16);
      display: grid;
      grid-template-columns: 360px 1fr;
      overflow: hidden;
      border: 1px solid rgba(15, 23, 42, 0.04);
    }

    @media (max-width: 1024px) {
      .shell {
        grid-template-columns: 1fr;
      }
      .panel.left {
        border-right: none !important;
        border-bottom: 1px solid rgba(15, 23, 42, 0.04);
      }
    }

    .panel {
      padding: clamp(28px, 4vw, 48px);
      position: relative;
    }

    .panel.left {
      background: #ffffff;
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 28px;
      border-right: 1px solid rgba(15, 23, 42, 0.04);
    }

    .panel.right {
      display: flex;
      flex-direction: column;
      gap: 24px;
    }

    h1 {
      margin: 0;
      font-size: clamp(1.8rem, 2vw + 1rem, 2.6rem);
      letter-spacing: -0.04em;
    }

    p.lead {
      margin: 0;
      color: var(--muted);
      font-size: 1rem;
      line-height: 1.6;
    }

    label {
      font-weight: 600;
      font-size: 0.95rem;
      color: var(--muted);
    }

    .input-row {
      display: flex;
      gap: 12px;
      flex-wrap: wrap;
    }

    input[type="password"] {
      flex: 1 1 260px;
      padding: 14px 16px;
      border-radius: 16px;
      border: 1px solid var(--border);
      background: #fff;
      font-size: 0.95rem;
      transition: border-color 0.2s ease, box-shadow 0.2s ease;
    }

    input[type="password"]:focus {
      outline: none;
      border-color: rgba(38, 98, 255, 0.75);
      box-shadow: 0 0 0 4px rgba(38, 98, 255, 0.18);
    }

    button {
      border: none;
      border-radius: 16px;
      padding: 14px 22px;
      font-size: 0.95rem;
      font-weight: 600;
      cursor: pointer;
      transition: transform 0.2s ease, box-shadow 0.2s ease, background 0.2s ease;
    }

    button.primary {
      background: var(--accent);
      color: #fff;
      box-shadow: 0 14px 32px rgba(38, 98, 255, 0.28);
    }

    button.primary:disabled {
      background: rgba(38, 98, 255, 0.38);
      cursor: not-allowed;
      box-shadow: none;
      transform: none;
    }

    button.primary:not(:disabled):hover {
      transform: translateY(-1px);
      box-shadow: 0 16px 34px rgba(38, 98, 255, 0.34);
    }

    button.talk {
      width: 100%;
      font-size: 1.05rem;
      padding: 18px 22px;
      background: #0f172a;
      color: #fff;
      letter-spacing: 0.02em;
      box-shadow: 0 18px 40px rgba(15, 23, 42, 0.25);
    }

    button.talk:disabled {
      background: rgba(15, 23, 42, 0.28);
      box-shadow: none;
      cursor: not-allowed;
    }

    .avatar-frame {
      position: relative;
      width: min(320px, 100%);
      aspect-ratio: 3 / 4;
      background: #ffffff;
      border-radius: 28px;
      display: flex;
      align-items: center;
      justify-content: center;
      box-shadow: inset 0 0 0 1px rgba(15, 23, 42, 0.06), 0 40px 80px rgba(15, 23, 42, 0.2);
      overflow: hidden;
    }

    .avatar-frame::after {
      content: "";
      position: absolute;
      inset: 18px;
      border-radius: 22px;
      background: radial-gradient(circle at 40% 20%, rgba(38, 98, 255, 0.12), transparent 65%);
      z-index: 0;
    }

    .avatar-frame img {
      width: 88%;
      max-width: 320px;
      height: auto;
      position: relative;
      z-index: 1;
      filter: drop-shadow(0 32px 60px rgba(15, 23, 42, 0.32));
      transition: transform 0.24s ease;
    }

    .avatar-frame img.speaking {
      transform: translateY(-6px) scale(1.03);
    }

    .status {
      display: flex;
      align-items: center;
      gap: 12px;
      font-size: 0.95rem;
      color: var(--muted);
    }

    .dot {
      width: 12px;
      height: 12px;
      border-radius: 50%;
      background: #cbd5f5;
      box-shadow: 0 0 0 6px rgba(203, 213, 225, 0.45);
      transition: background 0.3s ease, box-shadow 0.3s ease;
    }

    .dot.online {
      background: #34d399;
      box-shadow: 0 0 0 6px rgba(52, 211, 153, 0.25);
    }

    .log {
      flex: 1;
      min-height: 360px;
      background: rgba(255, 255, 255, 0.9);
      border-radius: 24px;
      border: 1px solid rgba(15, 23, 42, 0.05);
      padding: clamp(20px, 3vw, 32px);
      display: flex;
      flex-direction: column;
      gap: 18px;
      overflow-y: auto;
      scrollbar-width: thin;
    }

    .log::-webkit-scrollbar {
      width: 6px;
    }

    .log::-webkit-scrollbar-thumb {
      background: rgba(15, 23, 42, 0.12);
      border-radius: 999px;
    }

    .entry {
      display: flex;
      flex-direction: column;
      gap: 6px;
      background: rgba(38, 98, 255, 0.05);
      border-radius: 18px;
      padding: 16px 18px;
      box-shadow: inset 0 0 0 1px rgba(38, 98, 255, 0.06);
    }

    .entry.ai {
      background: rgba(15, 23, 42, 0.05);
      box-shadow: inset 0 0 0 1px rgba(15, 23, 42, 0.06);
    }

    .entry h3 {
      margin: 0;
      font-size: 0.85rem;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      color: var(--muted);
    }

    .entry p {
      margin: 0;
      font-size: 1rem;
      line-height: 1.6;
      color: var(--text);
    }

    .hint {
      margin: 0;
      font-size: 0.85rem;
      color: var(--muted);
      text-align: center;
    }

    .hidden {
      display: none !important;
    }

    .error {
      color: #ef4444;
      font-weight: 600;
    }

    .loader {
      width: 56px;
      height: 56px;
      border-radius: 50%;
      border: 6px solid rgba(38, 98, 255, 0.12);
      border-top-color: rgba(38, 98, 255, 0.75);
      animation: spin 1s linear infinite;
      margin: 32px auto 0;
    }

    @keyframes spin {
      to {
        transform: rotate(360deg);
      }
    }
  </style>
</head>
<body>
  <div class="shell">
    <section class="panel left">
      <div class="avatar-frame">
        <img id="avatar" src="arm_behind_mouth_closed.png" alt="AI avatar" />
      </div>
      <div class="status">
        <div class="dot" id="statusDot"></div>
        <span id="statusText">Disconnected</span>
      </div>
      <button class="talk" id="talkBtn" disabled>Hold to talk</button>
      <p class="hint">Press and hold while speaking. Release to send your message.</p>
      <div class="hint" id="errorText"></div>
    </section>
    <section class="panel right">
      <div>
        <h1>Gemini Voice Link</h1>
        <p class="lead">Authenticate with your Gemini API key, then converse naturally by holding the microphone button. Speech flows to Gemini, which listens, reasons, and replies with lifelike synthesis.</p>
      </div>
      <div>
        <label for="apiKey">Gemini API key</label>
        <div class="input-row">
          <input type="password" id="apiKey" placeholder="AIza..." autocomplete="off" />
          <button class="primary" id="connectBtn">Connect</button>
        </div>
      </div>
      <div class="status" id="sessionStatus">
        <div class="loader hidden" id="loader"></div>
        <span id="sessionText">Awaiting connection.</span>
      </div>
      <div class="log" id="conversation">
        <div class="hint">Your conversation transcript will appear here.</div>
      </div>
    </section>
  </div>
  <script>
    const STARTUP_FRAMES = [
      'a1.png',
      'a2.png',
      'a3.png',
      'a4.png',
      'a5.png',
      'a6.png',
      'a7.png'
    ];

    const POSES = {
      idle: {
        closed: 'arm_behind_mouth_closed.png',
        open: 'arm_behind_mouth_open.png'
      },
      expressive: {
        closed: 'arm_out_mouth_closed.png',
        open: 'arm_out_mouth_open.png'
      }
    };

    const GEMINI_MODELS = {
      chat: 'models/gemini-2.5-flash',
      tts: 'models/gemini-2.5-flash-preview-tts'
    };

    const apiBase = 'https://generativelanguage.googleapis.com/v1beta';
    const avatarEl = document.getElementById('avatar');
    const statusDot = document.getElementById('statusDot');
    const statusText = document.getElementById('statusText');
    const talkBtn = document.getElementById('talkBtn');
    const connectBtn = document.getElementById('connectBtn');
    const apiKeyInput = document.getElementById('apiKey');
    const sessionText = document.getElementById('sessionText');
    const loader = document.getElementById('loader');
    const conversationEl = document.getElementById('conversation');
    const errorText = document.getElementById('errorText');

    let audioContext;
    let mediaRecorder;
    let mediaStream;
    let isConnected = false;
    let isRecording = false;
    let isProcessing = false;
    let activeSpeechAnimation;
    let currentPose = 'idle';
    let currentMouthOpen = false;
    let conversationHistory = [];
    let apiKey = '';

    function setStatus({ online = false, text = '' }) {
      statusDot.classList.toggle('online', online);
      statusText.textContent = text;
    }

    function setSessionMessage(message, loading = false) {
      sessionText.textContent = message;
      loader.classList.toggle('hidden', !loading);
    }

    function showError(message = '') {
      errorText.textContent = message;
      errorText.classList.toggle('error', Boolean(message));
    }

    async function ensureAudioContext() {
      if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      }
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
      }
      return audioContext;
    }

    function playStartupSound() {
      return ensureAudioContext().then(ctx => {
        return new Promise(resolve => {
          const osc = ctx.createOscillator();
          const gain = ctx.createGain();
          osc.type = 'sawtooth';
          const now = ctx.currentTime;
          osc.frequency.setValueAtTime(220, now);
          osc.frequency.exponentialRampToValueAtTime(880, now + 0.9);
          gain.gain.setValueAtTime(0.0001, now);
          gain.gain.exponentialRampToValueAtTime(0.4, now + 0.05);
          gain.gain.exponentialRampToValueAtTime(0.0001, now + 1.2);
          osc.connect(gain).connect(ctx.destination);
          osc.start(now);
          osc.stop(now + 1.25);
          osc.onended = resolve;
        });
      });
    }

    function playStartupAnimation() {
      return new Promise(resolve => {
        let index = 0;
        const nextFrame = () => {
          avatarEl.src = STARTUP_FRAMES[index];
          index += 1;
          if (index < STARTUP_FRAMES.length) {
            setTimeout(nextFrame, 110);
          } else {
            setTimeout(() => {
              setAvatarPose('idle', false);
              resolve();
            }, 160);
          }
        };
        nextFrame();
      });
    }

    function setAvatarPose(pose = 'idle', mouthOpen = false) {
      currentPose = pose;
      currentMouthOpen = mouthOpen;
      const asset = POSES[pose][mouthOpen ? 'open' : 'closed'];
      avatarEl.src = asset;
      avatarEl.classList.toggle('speaking', mouthOpen);
    }

    function stopSpeakingAnimation() {
      if (activeSpeechAnimation) {
        cancelAnimationFrame(activeSpeechAnimation);
        activeSpeechAnimation = null;
      }
      setAvatarPose('idle', false);
    }

    function startSpeakingAnimation(analyser) {
      const buffer = new Uint8Array(analyser.fftSize);
      let mouthOpen = false;
      let lastSwitch = 0;
      const animate = timestamp => {
        analyser.getByteTimeDomainData(buffer);
        let sum = 0;
        for (let i = 0; i < buffer.length; i++) {
          const deviation = buffer[i] - 128;
          sum += deviation * deviation;
        }
        const rms = Math.sqrt(sum / buffer.length) / 128;
        const intensity = Math.min(rms * 4, 1);
        const expressive = intensity > 0.42;
        const minInterval = expressive ? 70 : 130;
        const maxInterval = expressive ? 120 : 220;
        const interval = maxInterval - (maxInterval - minInterval) * intensity;
        if (timestamp - lastSwitch >= interval) {
          mouthOpen = !mouthOpen;
          lastSwitch = timestamp;
        }
        setAvatarPose(expressive ? 'expressive' : 'idle', mouthOpen);
        activeSpeechAnimation = requestAnimationFrame(animate);
      };
      activeSpeechAnimation = requestAnimationFrame(animate);
    }

    async function playAudioFromBase64(base64Audio) {
      const ctx = await ensureAudioContext();
      const binary = atob(base64Audio);
      const len = binary.length;
      const bytes = new Uint8Array(len);
      for (let i = 0; i < len; i++) {
        bytes[i] = binary.charCodeAt(i);
      }
      const arrayBuffer = bytes.buffer.slice(bytes.byteOffset, bytes.byteOffset + bytes.byteLength);
      const sampleCount = arrayBuffer.byteLength / 2;
      const audioBuffer = ctx.createBuffer(1, sampleCount, 24000);
      const channelData = audioBuffer.getChannelData(0);
      const view = new DataView(arrayBuffer);
      for (let i = 0; i < sampleCount; i++) {
        const intSample = view.getInt16(i * 2, true);
        channelData[i] = intSample / 32768;
      }
      return new Promise(resolve => {
        const source = ctx.createBufferSource();
        const analyser = ctx.createAnalyser();
        analyser.fftSize = 2048;
        source.buffer = audioBuffer;
        source.connect(analyser);
        analyser.connect(ctx.destination);
        source.onended = () => {
          stopSpeakingAnimation();
          resolve();
        };
        stopSpeakingAnimation();
        setAvatarPose('idle', true);
        startSpeakingAnimation(analyser);
        source.start();
      });
    }

    function appendMessage(role, content, transcript = '') {
      const entry = document.createElement('div');
      entry.className = `entry ${role}`;
      const heading = document.createElement('h3');
      heading.textContent = role === 'ai' ? 'Gemini' : 'You';
      entry.appendChild(heading);

      if (transcript) {
        const transcriptEl = document.createElement('p');
        transcriptEl.innerHTML = `<strong>Transcript:</strong> ${transcript}`;
        entry.appendChild(transcriptEl);
      }

      const body = document.createElement('p');
      body.textContent = content;
      entry.appendChild(body);

      const emptyHint = conversationEl.querySelector('.hint');
      if (emptyHint) {
        emptyHint.remove();
      }
      conversationEl.appendChild(entry);
      conversationEl.scrollTop = conversationEl.scrollHeight;
      return entry;
    }

    function toBase64(arrayBuffer) {
      let binary = '';
      const bytes = new Uint8Array(arrayBuffer);
      const chunk = 0x8000;
      for (let i = 0; i < bytes.length; i += chunk) {
        const slice = bytes.subarray(i, i + chunk);
        binary += String.fromCharCode.apply(null, slice);
      }
      return btoa(binary);
    }

    async function requestGeminiResponse(audioBlob) {
      const arrayBuffer = await audioBlob.arrayBuffer();
      const base64Audio = toBase64(arrayBuffer);
      const contents = [...conversationHistory];
      contents.push({
        role: 'user',
        parts: [
          {
            inlineData: {
              mimeType: audioBlob.type || 'audio/webm;codecs=opus',
              data: base64Audio
            }
          },
          {
            text: 'The previous parts contain the latest voice message. Transcribe it and reply naturally.'
          }
        ]
      });

      let response;
      try {
        response = await fetch(`${apiBase}/${GEMINI_MODELS.chat}:generateContent`, {
          method: 'POST',
          mode: 'cors',
          headers: {
            'Content-Type': 'application/json',
            'x-goog-api-key': apiKey
          },
          body: JSON.stringify({
            systemInstruction: {
              role: 'system',
              parts: [
                {
                  text: 'You are a realtime voice companion. Each user turn arrives as audio. Return a strict JSON object with keys "transcript" (transcribed user speech) and "reply" (your spoken response). Keep replies concise and conversational. Do not add extra text outside JSON.'
                }
              ]
            },
            generationConfig: {
              responseMimeType: 'application/json'
            },
            contents
          })
        });
      } catch (err) {
        throw new Error('Network error while contacting Gemini. Confirm you are online and using a valid API key.');
      }

      if (!response.ok) {
        const detail = await response.text();
        throw new Error(`Gemini request failed (${response.status}): ${detail}`);
      }

      const data = await response.json();
      const text = data.candidates?.[0]?.content?.parts?.map(part => part.text || '').join('').trim();
      if (!text) {
        throw new Error('Gemini returned an empty response.');
      }

      let parsed;
      try {
        parsed = JSON.parse(text);
      } catch (err) {
        throw new Error('Gemini reply was not valid JSON: ' + text);
      }

      if (!parsed.reply) {
        throw new Error('Gemini reply JSON missing "reply" field.');
      }

      return parsed;
    }

    async function speakWithGemini(text) {
      let response;
      try {
        response = await fetch(`${apiBase}/${GEMINI_MODELS.tts}:generateContent`, {
          method: 'POST',
          mode: 'cors',
          headers: {
            'Content-Type': 'application/json',
            'x-goog-api-key': apiKey
          },
          body: JSON.stringify({
            contents: [
              {
                role: 'user',
                parts: [
                  { text }
                ]
              }
            ],
            config: {
              responseModalities: ['AUDIO'],
              speechConfig: {
                voiceConfig: {
                  prebuiltVoiceConfig: {
                    voiceName: 'Kore'
                  }
                }
              }
            }
          })
        });
      } catch (err) {
        throw new Error('Network error while requesting Gemini TTS.');
      }

      if (!response.ok) {
        const detail = await response.text();
        throw new Error(`TTS request failed (${response.status}): ${detail}`);
      }

      const data = await response.json();
      const audioPart = data.candidates?.[0]?.content?.parts?.find(part => part.inlineData?.data);
      const base64 = audioPart?.inlineData?.data;
      if (!base64) {
        throw new Error('Gemini TTS response missing audio data.');
      }
      await playAudioFromBase64(base64);
    }

    async function connect() {
      apiKey = apiKeyInput.value.trim();
      if (!apiKey) {
        showError('Enter your Gemini API key first.');
        return;
      }
      connectBtn.disabled = true;
      apiKeyInput.disabled = true;
      showError('');
      setSessionMessage('Spinning up the interface…', true);
      setStatus({ online: false, text: 'Connecting…' });
      try {
        await ensureAudioContext();
        await playStartupSound();
        await playStartupAnimation();
        setStatus({ online: true, text: 'Connected to Gemini' });
        setSessionMessage('Hold the button and speak to talk with Gemini.');
        talkBtn.disabled = false;
        isConnected = true;
      } catch (err) {
        showError(err.message);
        connectBtn.disabled = false;
        apiKeyInput.disabled = false;
        setSessionMessage('Connection failed. Check your API key and try again.');
        setStatus({ online: false, text: 'Disconnected' });
      } finally {
        loader.classList.add('hidden');
      }
    }

    async function startRecording() {
      if (!isConnected || isProcessing) return;
      showError('');
      setSessionMessage('Listening… release to send.', false);
      talkBtn.textContent = 'Listening…';
      if (!mediaStream) {
        try {
          mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        } catch (err) {
          showError('Microphone permission is required to talk.');
          setSessionMessage('Grant microphone access to continue.');
          talkBtn.textContent = 'Hold to talk';
          isRecording = false;
          talkBtn.disabled = false;
          return;
        }
      }
      mediaRecorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm;codecs=opus' });
      const chunks = [];
      mediaRecorder.ondataavailable = evt => {
        if (evt.data && evt.data.size > 0) {
          chunks.push(evt.data);
        }
      };
      mediaRecorder.onstop = () => handleRecordingStop(new Blob(chunks, { type: 'audio/webm;codecs=opus' }));
      mediaRecorder.start();
      isRecording = true;
    }

    async function handleRecordingStop(blob) {
      if (!isRecording) return;
      isRecording = false;
      talkBtn.textContent = 'Hold to talk';
      talkBtn.disabled = true;
      isProcessing = true;
      setSessionMessage('Sending audio to Gemini…', true);
      const placeholder = appendMessage('user', 'Processing your voice message…');

      try {
        const result = await requestGeminiResponse(blob);
        const transcript = result.transcript || '(no transcript)';
        const reply = result.reply.trim();
        conversationHistory.push({ role: 'user', parts: [{ text: transcript }] });
        conversationHistory.push({ role: 'model', parts: [{ text: reply }] });
        const body = placeholder.querySelector('p:last-child');
        if (body) {
          body.textContent = transcript;
        }
        appendMessage('ai', reply);
        setSessionMessage('Speaking…', true);
        await speakWithGemini(reply);
        setSessionMessage('Conversation ready. Hold to speak again.');
      } catch (err) {
        console.error(err);
        showError(err.message || 'Something went wrong.');
        setSessionMessage('Try again when ready.');
        const body = placeholder?.querySelector('p:last-child');
        if (body) {
          body.textContent = 'We could not process that voice message.';
        }
      } finally {
        isProcessing = false;
        talkBtn.disabled = false;
        loader.classList.add('hidden');
        stopSpeakingAnimation();
      }
    }

    function stopRecording() {
      if (!isRecording || !mediaRecorder) return;
      setSessionMessage('Processing…', true);
      mediaRecorder.stop();
    }

    connectBtn.addEventListener('click', () => {
      if (!isConnected) {
        connect();
      }
    });

    talkBtn.addEventListener('pointerdown', () => {
      if (!isConnected || isProcessing) return;
      startRecording();
    });

    talkBtn.addEventListener('pointerup', () => {
      if (isRecording) {
        stopRecording();
      }
    });

    talkBtn.addEventListener('pointerleave', () => {
      if (isRecording) {
        stopRecording();
      }
    });

    talkBtn.addEventListener('pointercancel', () => {
      if (isRecording) {
        stopRecording();
      }
    });

    window.addEventListener('beforeunload', () => {
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
      }
    });
  </script>
</body>
</html>
